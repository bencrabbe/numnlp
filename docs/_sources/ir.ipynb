{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0c3ad73",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d27dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8f0530",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d43be1a-dff1-4f80-a69d-8052501ac9d6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Information retrieval exercise\n",
    "===\n",
    "\n",
    "\n",
    "This exercise amounts to design a toy vector space information retrieval\n",
    "on the CISI data set.  The system can be augmented with latent representations using Latent Semantic Analysis\n",
    "(or Latent Semantic Indexing) methodologies.    \n",
    "\n",
    "The data set is small enough to allow an in-class exercise with naive implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738c1fed-c5aa-4cab-bbb9-7380fbf93899",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Download packages and data\n",
    "----\n",
    "\n",
    "The first step is to download required packages and data...\n",
    "\n",
    "**WARNING** No other downloaded packages and data sets are allowed for this exercise than those actually downloaded here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0e0809-c057-42a5-9af8-6585ea3c4e32",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a77ae05242d653061530d9522f2f423",
     "grade": false,
     "grade_id": "cell-6ad8c16dd94b4a40",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "INSTALL = True # set this variable to True to download the necessary materials\n",
    "\n",
    "if INSTALL:\n",
    "    !pip install numpy\n",
    "    !pip install spacy\n",
    "    !pip install gdown\n",
    "    !python -m spacy download en_core_web_sm\n",
    "    !pip install ir_measures \n",
    "    \n",
    "    import gdown\n",
    "    gdown.download('https://drive.google.com/uc?id=14BbZBflc0rkkvZMA_DRdd3xvQZuo_q2Z', 'cisi_queries.json')\n",
    "    gdown.download('https://drive.google.com/uc?id=1wl6Rh5PvI6_kV9LSiBeTOVfuqM_qfA5-',  'cisi_qrels.json')\n",
    "    gdown.download('https://drive.google.com/uc?id=1MIEDbQt2NBAhJjngN4Nr2JUnaKdZ2_YJ', 'cisi_all.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23741c3b-0655-469b-8a3e-4275e6ab0625",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ded36b493656daeacb551210afc0a4eb",
     "grade": false,
     "grade_id": "cell-bca6e74bd8a82771",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# The docset is the set of documents used in this exercise\n",
    "# queries is the set of queries used for testing the search engine\n",
    "\n",
    "with open('cisi_all.json') as docstream:\n",
    "    docset     = json.loads(docstream.read())\n",
    "\n",
    "with open('cisi_queries.json') as qstream:\n",
    "    queries     = json.loads(qstream.read())\n",
    "\n",
    "print('Total number of documents',len(docset))\n",
    "print('Total number of queries',len(queries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8269c031-0533-4830-b1a9-9c78a5bcbaf5",
   "metadata": {},
   "source": [
    "View documents\n",
    "-----\n",
    "\n",
    "Documents are stored as a list of dictionaries. \n",
    "The following code displays the first $k$ elements of this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91550f54-28b8-4020-8687-f1a6113a5b1a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35284d9bcfc8a8bf23eb0dc743337016",
     "grade": false,
     "grade_id": "cell-aa7f7e4ad6c812dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def show_docs(start=0,end=4):\n",
    "    for doc in docset[start:end]:\n",
    "        print(doc)\n",
    "        print('-'*80)\n",
    "\n",
    "show_docs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8e5829-9fa5-46fc-b411-99bd48a5a32f",
   "metadata": {},
   "source": [
    "View queries\n",
    "------\n",
    "\n",
    "Queries are stored as a list of dictionaries. \n",
    "The following code displays the first $k$ elements of this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f799fc05-8627-4290-81f2-3d0897229edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_queries(start=0,end=3):\n",
    "    for query in queries[start:end] :\n",
    "        print(query)\n",
    "        print('-'*80)\n",
    "\n",
    "show_queries()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702601a5-cf17-4f08-82ff-e302fbfd3865",
   "metadata": {},
   "source": [
    "Preprocess data\n",
    "------\n",
    "\n",
    "The first exercise amounts to design a preprocessing function for documents and queries.\n",
    "This preprocessing function typically involves:\n",
    "\n",
    "- Text normalisation (lowercase, removal of punctuation)\n",
    "- Lemmatisation and or stemmatisation\n",
    "- Removal of stop words\n",
    "\n",
    "You are allowed to use the `spacy` library here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56f79bb-f8b0-4f92-b51f-69829dc22ebd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf4665f759ff705e363700a7f04b895c",
     "grade": false,
     "grade_id": "cell-4c6f9fcbf90802cd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import string\n",
    "\n",
    "\n",
    "tokenizer = spacy.load('en_core_web_sm')\n",
    "stopwords = spacy.util.get_lang_class('en').Defaults.stop_words\n",
    "\n",
    "#You may customize stop words\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "def preproc_doc(text,lower=True,use_stopwords=True):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        text(string)   : the input string\n",
    "        lower(bool)    : whether to lowercase the text or not\n",
    "        stopwords(bool): whether to remove stopwords from text or not\n",
    "    Returns:\n",
    "        string. The preprocessed text\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb144fcd-1959-41a9-92f4-b17566720c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You may test your preprocessing on documents and queries here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c89861-6f7e-4ecf-b7b2-f1085c6e8ef9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c1cfd0b498077fa501cc8cb3352dd734",
     "grade": true,
     "grade_id": "cell-045472e2424aba6e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Automatic tests #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2737b07d-2e10-4c14-b853-eb91ba47641c",
   "metadata": {},
   "source": [
    "Create vocabulary\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4361ef4-d0ad-4906-b624-af48fe50d83b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc07a6ced12244ab4e584bcb75dc4b61",
     "grade": false,
     "grade_id": "cell-4bde94a5d0a3f78e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def make_vocab(docset,max_vocab_size=50000):\n",
    "    \"\"\"\n",
    "    Extracts the vocabulary from the docset as a list of unique word forms\n",
    "    Args:\n",
    "        docset (list): the list of documents\n",
    "        max_vocab_size (int): the maximum number of entries in the vocabulary\n",
    "    Return:\n",
    "       list of strings. The vocabulary list made of the most frequent words in case of cutoff\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def index_vocab(vocab_list):\n",
    "    \"\"\"\n",
    "    Turns a list of words into a python dictionary mapping words to indexes\n",
    "    Args:\n",
    "       vocab_list (list) : a list of strings\n",
    "    Returns:\n",
    "       a dict.\n",
    "    \"\"\"\n",
    "    return dict( (word,idx) for idx, word in enumerate(vocab_list))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a25b50a-6efc-4b03-af5c-9bd0c411371b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5605f6c45e87c8fe5ac1c20c85b1ea11",
     "grade": true,
     "grade_id": "cell-d8ad7fdff453a961",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3f4833-3f16-44ea-a1d2-3268b9f9df2f",
   "metadata": {},
   "source": [
    "Term document matrix\n",
    "----\n",
    "\n",
    "These are functions for creating the term document matrix and some of its transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aee11bf-a50f-408f-9b73-90e259f4f194",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79051d680952abf8af723b42e807f3fd",
     "grade": false,
     "grade_id": "cell-6a81eb401fc68b04",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def bow_TXD(docset,vocab_list,vocabulary=None):\n",
    "    \"\"\"\n",
    "    Creates a term document matrix from bags of words\n",
    "    Args:\n",
    "        docset (list) : the list of documents \n",
    "        vocab_list()  : the vocabulary list\n",
    "        vocabulary(dict): the vocabulary dictionary indexed by index_vocab(...) or None\n",
    "    Returns:\n",
    "       a numpy array. A term document matrix with vocab size lines and documents size columns\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937e3b61-a736-452f-871d-7ce668064dcf",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ecd3df5eb1fff4c40e45d2b3333459a",
     "grade": false,
     "grade_id": "cell-41b88289f463ce3a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tf(docvec):\n",
    "    \"\"\"\n",
    "    Computes the true frequency from a vector of raw counts.\n",
    "    Args :\n",
    "       docvec (numpy.array) : a vector of word counts\n",
    "    Returns:\n",
    "      numpy.array. A vector of word frequencies\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def idf(termvec):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes the idf scores from a vector of raw counts\n",
    "    Args:\n",
    "       termvec (numpy.array): a vector of occurrence counts in the set of documents for some term t\n",
    "    Returns:\n",
    "       float. The idf score for the term t computed as log ( D / |counts(t,d) > 0| )  \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def idfvec(tdmat):\n",
    "    \"\"\"\n",
    "    Computes the idf scores for a full term document matrix\n",
    "    \n",
    "    Args:\n",
    "       tdmat (numpy.array): a term document matrix\n",
    "    Returns:\n",
    "       numpy.array with idf scores, one score for each word in the vocabulary \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "def tfidf(doc_vec,idf_vec):\n",
    "    \"\"\"\n",
    "    Computes tf-idf scores from a vector of raw counts for a document  \n",
    "    Args:\n",
    "       doc_vec (numpy.array): a vector of word counts\n",
    "       idf_vec (numpy.array): a vector of word idf scores\n",
    "    Returns:\n",
    "       numpy.array with tfidf scores\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea3b131-8b97-4661-874a-0635f4779b07",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "04c2a7e531583b4db02bd05dc895251d",
     "grade": true,
     "grade_id": "cell-6f4e55fcee5a07b5",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559d6407-93cb-4ef8-8e8b-94e53950e9de",
   "metadata": {},
   "source": [
    "Querying \n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452595e5-b85d-41c3-985e-64c12becaad5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a6d417654d5533d0aeadc2d82b33a84e",
     "grade": false,
     "grade_id": "cell-b9bb3bb1f59d05d1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "def score_doc(qvec,docvec):\n",
    "    \"\"\"\n",
    "    Scores the query against a document\n",
    "    Args:\n",
    "        qvec  (numpy.array): the vector for the query\n",
    "        docvec(numpy.array): the vector for the document\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fced4943-71f6-493c-9342-2a28fe2c158a",
   "metadata": {},
   "source": [
    "We can also use Latent Semantic Analysis for document representation. This amounts to compute latent vectors for documents\n",
    "with SVD decomposition:\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = \\mathbf{T}\\Sigma\\mathbf{D}^\\top\n",
    "$$\n",
    "\n",
    "where the latent document vectors are columns of $\\mathbf{D}$. \n",
    "The query vectors built naturally as a single columns of $\\mathbf{X}$ can be mapped to their reduced transformation\n",
    "as:\n",
    "\n",
    "$$\n",
    "\\Sigma^{-1}\\mathbf{T}^\\top \\mathbf{X} = \\mathbf{D}^\\top\n",
    "$$\n",
    "\n",
    "this can be justified by the following rewriting of the SVD decomposition:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{X} &= \\mathbf{T}\\Sigma\\mathbf{D}^\\top\\\\\n",
    "\\mathbf{T}^\\top \\mathbf{X} &= \\Sigma\\mathbf{D}^\\top\\\\\n",
    "\\Sigma^{-1}\\mathbf{T}^\\top \\mathbf{X} &= \\mathbf{D}^\\top\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "and by recalling that inverses of orthonormal matrices are their transpose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284bd87b-442e-496e-8c8a-5460160ca2ca",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d2f2da9e004a3ecb7184b797dfe16df",
     "grade": false,
     "grade_id": "cell-d3fef7218ce58808",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import ir_measures\n",
    "from ir_measures import Qrel, ScoredDoc, P, R, nDCG\n",
    "\n",
    "from numpy.linalg import svd\n",
    "\n",
    "\n",
    "class IRModel:\n",
    "\n",
    "    def __init__(self,docset, use_tfidf=True, use_svd=False, max_vocab_size=20000, k = None):\n",
    "        \"\"\"\n",
    "        This class gathers the query evaluations functionalities.\n",
    "        In case of efficiency issues, try to reduce the vocabulary size or k.\n",
    "        (this won't scale up anyway for large datasets)   \n",
    "        Args:\n",
    "            docset (list)  : the list of documents as dictionaries\n",
    "            use_tfidf(bool): controls whether the term document matrix is transformed with tf-idf\n",
    "            use_svd  (bool): controls whether SVD is used to reduce dimensionality\n",
    "            k (int)        : the size of the latent space for svd\n",
    "            max_vocab_size (int): maximum size for the vocabulary.\n",
    "        \"\"\"\n",
    "        self.use_tfidf = use_tfidf\n",
    "        self.use_svd   = use_svd\n",
    "        \n",
    "        print('Building vocabulary...')\n",
    "        vocab_list      = make_vocab(docset,max_vocab_size)\n",
    "        self.vocabulary = index_vocab(vocab_list)\n",
    "        \n",
    "        print('Building term document matrix...')\n",
    "        tdmat           = bow_TXD(docset,vocab_list,self.vocabulary)\n",
    "\n",
    "        \n",
    "        if self.use_tfidf:\n",
    "\n",
    "            #update tdmat using the tfidf transformation\n",
    "            \n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "        \n",
    "        if self.use_svd:\n",
    "\n",
    "            #assign self.U, self.sigma and tdmat using truncated SVD decomposition\n",
    "            #read the doc \n",
    "            print('Computing SVD...')\n",
    "\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "        \n",
    "        else:\n",
    "            print('shape',tdmat.shape)            \n",
    "\n",
    "        #Stores document vectors with indices starting at 1 (to be compatible with dataset !)  \n",
    "        self.docvecs = {str(idx+1):docvec for idx,docvec in enumerate(tdmat.T)}\n",
    "    \n",
    "        print('done')\n",
    "\n",
    "\n",
    "    \n",
    "    def query2vec(self,query):\n",
    "        \"\"\"\n",
    "        Encodes a query on a vector.\n",
    "        Args :\n",
    "           query (string): the query text\n",
    "        Returns:\n",
    "           numpy.array : the vector for this query\n",
    "        \"\"\"\n",
    "        text = preproc_doc(query)\n",
    "        \n",
    "        counts = Counter(text.split())\n",
    "        docvec = np.zeros(len(self.vocabulary)) \n",
    "        for word in counts.elements():\n",
    "            if word in self.vocabulary:\n",
    "                idx = self.vocabulary[word]\n",
    "                docvec[idx] = counts[word]\n",
    "        \n",
    "        if self.use_tfidf: \n",
    "    \n",
    "            #maps the docvec with tf-idf\n",
    "            \n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "        \n",
    "        if self.use_svd:\n",
    "            \n",
    "            #maps the docvec to the lower dimensional space \n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        return docvec\n",
    "\n",
    "    def make_run(self,queries, kresults=50,verbose=False):\n",
    "        \"\"\"\n",
    "        A run is the list of the model search results for each query in the list of queries.\n",
    "\n",
    "        Args:\n",
    "           queries (list): a list of queries as dictionaries\n",
    "           kresults (int): the max number of results per query\n",
    "           verbose (bool): a flag controlling whether we want to display verbose debugging and analysis messages\n",
    "        Returns:\n",
    "           a list of ir_measures.ScoredDoc objects that can be used as is for quantitative evaluation\n",
    "        \"\"\"\n",
    "        \n",
    "        run = [ ]\n",
    "        for query in queries:\n",
    "            \n",
    "            qvec       = self.query2vec(query['text']) \n",
    "\n",
    "            #create a list of scores for documents given this query and truncate it with cutoff kresults\n",
    "            #for each document in self.docvecs create a couple (score,doc_id) and add it to the list\n",
    "\n",
    "            #scores = ...\n",
    "\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "            \n",
    "            #Required for scoring the evaluation\n",
    "            for score, doc_id in scores:\n",
    "                run.append(ScoredDoc(query['query_id'],doc_id,score))\n",
    "        return run\n",
    "\n",
    "    \n",
    "    def supervised_query(self,qidx, queries,qrels):\n",
    "        \"\"\"\n",
    "        Prints the results of a query execution. Useful for debugging and/or qualitative analysis \n",
    "        Args:\n",
    "            qidx    (int): the ID of the query given by qrels\n",
    "            queries(list): list of queries as dictionaries\n",
    "            qrels  (list): list of qrels as Qrel objects\n",
    "        \"\"\"\n",
    "        #Optional exercise : \n",
    "        #    given a query ID, print the query and the reference results\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bc50b6-f691-4dda-b56f-af44bc3105ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your best model here, you may try several sets of parameters or even search programmatically for good models\n",
    "\n",
    "search_model = IRModel(docset,use_svd=False,max_vocab_size=1000,k=None)\n",
    "\n",
    "# your best model has to be assigned to the search_model variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00c7061-6835-4f6a-a8da-bf6b22884e01",
   "metadata": {},
   "source": [
    "Evaluation section\n",
    "-------\n",
    "The evaluation relies on the `ir_measures` library.\n",
    "This library evaluates so called \"runs\" returned by the model against reference solution\n",
    "A run is a list of ScoredDoc. Each query in the evaluation set generates some answers stored as ScoredDoc.\n",
    "The ScoredDoc list is compared to the reference solution stored as a qrels list\n",
    "\n",
    "We will evaluate against nDCG@5 , P@5 and R@5 metrics.\n",
    "Find out what these metrics actually mean on the web\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03634ced-6478-40df-af5e-5ae54aa0dcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading reference solutions for the queries in all_qrels variable\n",
    "\n",
    "with open('cisi_qrels.json') as qrels:\n",
    "    all_qrels = [Qrel(QREL['query_id'],QREL['doc_id'],QREL['relevance']) for QREL in json.loads(qrels.read())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fbe2d6-864b-4338-b441-39f83594e295",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1e7c79d750e7dbf74d200a60324f76f",
     "grade": false,
     "grade_id": "cell-856b4cb23527b377",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#This cell cannot be modified !#\n",
    "\n",
    "#Computes evaluation\n",
    "best_run   = search_model.make_run(queries,kresults=5,verbose=False)\n",
    "evaluation = ir_measures.calc_aggregate([nDCG@5, P@5, R@5 ], all_qrels, best_run)\n",
    "\n",
    "#Prints the evaluation results\n",
    "print('Global evaluation')\n",
    "print(' | '.join(  f'{key}:{val}' for key, val in evaluation.items()))\n",
    "print('='*80)\n",
    "print()\n",
    "\n",
    "for metric in ir_measures.iter_calc( [nDCG@5, P@5, R@5 ], all_qrels, best_run):\n",
    "    print(f'query id = {metric.query_id}| measure = {metric.measure}| value = {metric.value}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a9fdc7-8bdb-4a24-b5b7-5a14df1b79a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6786d6-47c7-45b1-8456-00c97a17fc6a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3003f60cbe11446183f54cb5c6068277",
     "grade": true,
     "grade_id": "cell-cf459472946a59d5",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f499ef-82e5-49fc-bae2-f13cd065b33f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db0e9b81084530c5722aed2bf5f4fbab",
     "grade": true,
     "grade_id": "cell-5ef239cb387b1333",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78111b5-43c2-4854-a7db-05893f6706b5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "590778cf9aa78e6bc666a384e973b4bf",
     "grade": true,
     "grade_id": "cell-5f5ba0cb56e055f4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1db1320-49ad-4266-8261-774b786e8ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
