

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Applications to statistical analysis : latent semantic analysis &#8212; Numerical methods in NLP (foundations)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=bd9e20870c6007c4c509" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=bd9e20870c6007c4c509" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=bd9e20870c6007c4c509" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=bd9e20870c6007c4c509" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=bd9e20870c6007c4c509" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=bd9e20870c6007c4c509" />
  <script src="_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=bd9e20870c6007c4c509"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'stats';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Information retrieval exercise" href="ir.html" />
    <link rel="prev" title="Applications to graph analysis : the PageRank algorithm" href="graphs.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <header>
  
    <div class="bd-header navbar navbar-expand-lg bd-navbar">
    </div>
  
  </header>

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logoUPC.png" class="logo__image only-light" alt="Numerical methods in NLP (foundations) - Home"/>
    <script>document.write(`<img src="_static/logoUPC.png" class="logo__image only-dark" alt="Numerical methods in NLP (foundations) - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Numerical methods for Natural Language Processing
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="vectors.html">Vectors and vector spaces</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="numpy_exercises.html">Numpy exercises</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="euclid.html">The euclidean space</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="Euclid_exercises.html">Euclidean spaces : exercises</a></li>

<li class="toctree-l2"><a class="reference internal" href="euclid_appendix.html">Appendix to Euclidean spaces</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="vec2text.html">Applications to information retrieval</a></li>
<li class="toctree-l1"><a class="reference internal" href="matrices.html">Matrices</a></li>
<li class="toctree-l1"><a class="reference internal" href="graphs.html">Applications to graph analysis : the PageRank algorithm</a></li>
<li class="toctree-l1 current active has-children"><a class="current reference internal" href="#">Applications to statistical analysis : latent semantic analysis</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="ir.html">Information retrieval exercise</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="optim.html">Optimization basics</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="optim_exercises.html">Optimization exercises</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="http://github.com/bencrabbe/numnlp/issues/new?title=Issue%20on%20page%20%2Fstats.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button"
   title="Open an issue"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/stats.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Applications to statistical analysis : latent semantic analysis</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-algebra-for-descriptive-multivariate-statistics">Linear algebra for descriptive multivariate statistics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#covariance-matrices">Covariance matrices</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#singular-value-decomposition">Singular Value Decomposition</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#low-rank-representation">Low Rank representation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#latent-semantic-analysis">Latent Semantic Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-in-python">Example in Python</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lsa-and-visualisation">LSA and visualisation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topic-analysis">Topic analysis</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="applications-to-statistical-analysis-latent-semantic-analysis">
<h1>Applications to statistical analysis : latent semantic analysis<a class="headerlink" href="#applications-to-statistical-analysis-latent-semantic-analysis" title="Permalink to this heading">#</a></h1>
<p>This chapter essentially provides an application of the spectral theorem to data analysis
with a focus on Latent Semantic Analysis, a foundational method of textual data analysis.</p>
<p>The methods described here are mainly used to get low rank representations of multivariate high dimensional statistical data.
High dimensional data is the classical kind of data used in language modeling.
Low rank representations are used to visualize and/or to smooth this kind of data</p>
<section id="linear-algebra-for-descriptive-multivariate-statistics">
<h2>Linear algebra for descriptive multivariate statistics<a class="headerlink" href="#linear-algebra-for-descriptive-multivariate-statistics" title="Permalink to this heading">#</a></h2>
<p>Recall that a standard data set such as the <em>Iris</em>  is naturally viewed as a matrix</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>Sepal Length</p></th>
<th class="head"><p>Sepal Width</p></th>
<th class="head"><p>Petal Length</p></th>
<th class="head"><p>Petal Width</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>5.1</p></td>
<td><p>3.5</p></td>
<td><p>1.4</p></td>
<td><p>0.2</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>4.9</p></td>
<td><p>3.0</p></td>
<td><p>1.4</p></td>
<td><p>0.2</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>4.7</p></td>
<td><p>3.2</p></td>
<td><p>1.3</p></td>
<td><p>0.2</p></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p>4.6</p></td>
<td><p>3.1</p></td>
<td><p>1.5</p></td>
<td><p>0.2</p></td>
</tr>
</tbody>
</table>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{X}
\begin{bmatrix}
| &amp; | &amp; | &amp; |\\
    \mathbf{x}_1&amp;\mathbf{x}_2 &amp; \mathbf{x}_3 &amp; \mathbf{x}_4\\
| &amp; | &amp; | &amp; |
\end{bmatrix}	
\end{split}\]</div>
<p>where each column <span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span> represents a statistical variable.
Let us start by relating common statistical summary metrics to linear algebra.</p>
<ul class="simple">
<li><p>The <strong>mean vector</strong> of a vector <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathbb{R}^n\)</span> is the vector:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\bar{\mathbf{x}} = \mu \mathbf{1}_n \qquad (\mu = \frac{1}{n}\sum_{i=1}^n x_i) 
\]</div>
<ul class="simple">
<li><p>Let <span class="math notranslate nohighlight">\(\mathbf{x}_c \in \mathbb{R}^n\)</span>  be the centered vector :</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbf{x}_c =  \mathbf{x} - \bar{\mathbf{x}}
\]</div>
<ul class="simple">
<li><p>The <strong>variance</strong> of the vector <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> is the scalar:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\text{var}(\mathbf{x}) = \frac{1}{n}\mathbf{x}_c^\top \mathbf{x}_c
\]</div>
<ul class="simple">
<li><p>The <strong>standard deviation</strong> of the vector  <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> is as scalar proportional to the norm of <span class="math notranslate nohighlight">\(\mathbf{x}_c\)</span>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\sigma(\mathbf{x}) =  \frac{1}{n}  || \mathbf{x}_c ||
\]</div>
<ul class="simple">
<li><p>The <strong>covariance</strong> of vectors  <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathbb{R}^n\)</span>  and  <span class="math notranslate nohighlight">\(\mathbf{y} \in \mathbb{R}^n\)</span> is proportional to the dot product of <span class="math notranslate nohighlight">\(\mathbf{x}_c\)</span> and <span class="math notranslate nohighlight">\(\mathbf{y}_c\)</span>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\text{cov}(\mathbf{x}, \mathbf{y}) =  \frac{1}{n} \mathbf{x}_c^\top \mathbf{y}_c
\]</div>
<ul class="simple">
<li><p>The <strong>correlation</strong> of vectors  <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathbb{R}^n\)</span>  and  <span class="math notranslate nohighlight">\(\mathbf{y} \in \mathbb{R}^n\)</span></p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\text{cor}(\mathbf{x},\mathbf{y}) = \frac{\mathbf{x}_c^\top \mathbf{y}_c}{ ||\mathbf{x}_c|| \, ||\mathbf{y}_c || } 
\]</div>
<div class="tip admonition">
<p class="admonition-title">Tip</p>
<p>In practice it is often practical to compute correlations from centered unit vectors <span class="math notranslate nohighlight">\(\mathbf{x}_u\)</span> with norm <span class="math notranslate nohighlight">\(||\mathbf{x}_u || = 1\)</span>. In this case computing the correlation reduces to computing a dot product:</p>
<div class="math notranslate nohighlight">
\[
\text{cor}(\mathbf{x},\mathbf{y}) = \frac{\mathbf{x}^\top_u \mathbf{y}_u}{||\mathbf{x}_u||\, ||\mathbf{y}_u || }
= \frac{\mathbf{x}^\top_u \mathbf{y}_u}{1 \times 1} = \mathbf{x}^\top_u \mathbf{y}_u
\]</div>
<p>Such vectors are obtained from a data matrix by centering and normalizing:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}_u = \frac{\mathbf{x} - \bar{\mathbf{x}}}{||\mathbf{x} - \bar{\mathbf{x}}||} =  \frac{\mathbf{x} - \bar{\mathbf{x}}}{||\mathbf{x}||}
\]</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>There is an important connection between descriptive statistics and euclidean geometry. The correlation coefficient
is nothing else than a cosine measure between two centered data vectors while the standard deviation is proportional to the norm of a data vector. Further connections can be established, for instance to say that two data vectors are statistically independent is equivalent to say that the two vectors are orthogonal.</p>
</div>
</section>
<section id="covariance-matrices">
<h2>Covariance matrices<a class="headerlink" href="#covariance-matrices" title="Permalink to this heading">#</a></h2>
<p>Observe that we can compute the covariance between all couples of
(centered) data column vectors <span class="math notranslate nohighlight">\(\mathbf{x}_1 \ldots \mathbf{x}_m\)</span> by a single matrix product.
Let <span class="math notranslate nohighlight">\(\mathbf{X}\in \mathbb{R}^{n\times m}\)</span> then the resulting covariance matrix is:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\frac{1}{n}
\mathbf{X}^\top\mathbf{X} = 
\frac{1}{n}
\begin{bmatrix}
\mathbf{x}^\top_1 \mathbf{x}_1&amp; \cdots &amp; \mathbf{x}_1^\top \mathbf{x}_m \\
\vdots &amp; \ddots &amp; \vdots\\
\mathbf{x}^\top_m \mathbf{x}_1&amp;\cdots&amp;\mathbf{x}^\top_m \mathbf{x}_m
\end{bmatrix}
\end{split}\]</div>
<p>which is a symmetric square matrix of size <span class="math notranslate nohighlight">\(m\times m\)</span>.</p>
<div class="tip admonition">
<p class="admonition-title">Example</p>
<p>For the full <a class="reference external" href="https://en.wikipedia.org/wiki/Iris_flower_data_set">Iris</a> data set, the covariance matrix is a <span class="math notranslate nohighlight">\(4\times 4\)</span> matrix summarizing
the scatter plot given in the figure below:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\frac{1}{m}
\mathbf{X}^\top\mathbf{X} = 
\begin{bmatrix}
0.68 &amp; -0.04 &amp;  1.27 &amp; 0.51\\
-0.04&amp; 0.18  &amp; -0.32 &amp; -0.12\\
1.27 &amp; -0.32 &amp;  3.11 &amp;  1.29\\
0.51 &amp; -0.12 &amp;  1.29 &amp; 0.58
\end{bmatrix}
\end{split}\]</div>
<p>the diagonal of the covariance matrix stores the variance of each data column</p>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="_images/185327790c8e67e6c80670986ed26011f47125e414f57f752f355bebb768119c.png" src="_images/185327790c8e67e6c80670986ed26011f47125e414f57f752f355bebb768119c.png" />
</div>
</div>
<p>Another covariance matrix can be computed  by picking data line vectors  <span class="math notranslate nohighlight">\(\mathbf{x}_1 \ldots \mathbf{x}_m\)</span>, the resulting matrix is then:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\frac{1}{m}
\mathbf{X}\mathbf{X}^\top = 
\frac{1}{m}
\begin{bmatrix}
\mathbf{x}_1 \mathbf{x}_1^\top &amp; \cdots &amp; \mathbf{x}_1 \mathbf{x}_n^\top \\
\vdots &amp; \ddots &amp; \vdots\\
\mathbf{x}_n \mathbf{x}_1^\top &amp;\cdots&amp;\mathbf{x}_n \mathbf{x}_n^\top
\end{bmatrix}
\end{split}\]</div>
<p>which is a symmetric square matrix of size <span class="math notranslate nohighlight">\(n\times n\)</span>.</p>
<div class="tip admonition">
<p class="admonition-title">Example</p>
<p>The <strong>term document matrix</strong> is a classical method for encoding a collection of textual data sets.
For the Shakespeare example repeated here, it makes sense to compute both covariance matrices</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>Antony and Cleopatra</p></th>
<th class="head"><p>Julius Caesar</p></th>
<th class="head"><p>The Tempest</p></th>
<th class="head"><p>Hamlet</p></th>
<th class="head"><p>Othello</p></th>
<th class="head"><p>Macbeth</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Antony</p></td>
<td><p>157</p></td>
<td><p>73</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p>Brutus</p></td>
<td><p>4</p></td>
<td><p>157</p></td>
<td><p>0</p></td>
<td><p>2</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>Caesar</p></td>
<td><p>232</p></td>
<td><p>227</p></td>
<td><p>0</p></td>
<td><p>2</p></td>
<td><p>1</p></td>
<td><p>8</p></td>
</tr>
<tr class="row-odd"><td><p>Calpurnia</p></td>
<td><p>0</p></td>
<td><p>10</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>Cleopatra</p></td>
<td><p>57</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>mercy</p></td>
<td><p>2</p></td>
<td><p>0</p></td>
<td><p>3</p></td>
<td><p>8</p></td>
<td><p>5</p></td>
<td><p>5</p></td>
</tr>
<tr class="row-even"><td><p>worser</p></td>
<td><p>2</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
</tr>
</tbody>
</table>
<p>The matrix <span class="math notranslate nohighlight">\( \frac{1}{n}\mathbf{X}^\top\mathbf{X}\)</span> is again the covariances computed for column (document) variables
and the matrix  <span class="math notranslate nohighlight">\(\frac{1}{m}\mathbf{X}\mathbf{X}^\top\)</span> is the matrix computed for line (term) variables.</p>
</div>
</section>
<section id="singular-value-decomposition">
<h2>Singular Value Decomposition<a class="headerlink" href="#singular-value-decomposition" title="Permalink to this heading">#</a></h2>
<p>The Singular Value Decomposition theorem generalizes the diagonalization and spectral theorems to rectangular matrices.</p>
<div class="proof theorem admonition" id="svd-theorem">
<p class="admonition-title"><span class="caption-number">Theorem 3 </span> (SVD theorem )</p>
<section class="theorem-content" id="proof-content">
<p>The singular value decomposition theorem states that any matrix <span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbf{R}^{n\times m}\)</span> is decomposable as the product of 3 matrices:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{X} = \mathbf{U}\boldsymbol\Sigma \mathbf{V}^\top
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{U}\in \mathbb{R}^{n\times r} ,\mathbf{V}^\top \in \mathbb{R}^{r\times m} \)</span> and <span class="math notranslate nohighlight">\(\Sigma \in \mathbb{R}^{r\times r}\)</span>.
<span class="math notranslate nohighlight">\(\mathbf{U}\)</span> is a matrix whose columns are orthogonal left singular vectors while  <span class="math notranslate nohighlight">\(\mathbf{V}^\top\)</span> is a matrix whose lines are right singular vectors.
<span class="math notranslate nohighlight">\(\boldsymbol\Sigma\)</span> is a diagonal matrix whose diagonal <span class="math notranslate nohighlight">\(\sigma_1\ldots \sigma_r\)</span> are  non zero singular values.</p>
</section>
</div><p>The theorem is best interpreted by considering the covariance matrices:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{X}^\top\mathbf{X} = (\mathbf{U}\boldsymbol\Sigma\mathbf{V}^\top)^\top (\mathbf{U}\boldsymbol\Sigma\mathbf{V}^\top) =  (\mathbf{V}\boldsymbol\Sigma\mathbf{U}^\top)  (\mathbf{U}\boldsymbol\Sigma\mathbf{V}^\top) =  \mathbf{V}\boldsymbol\Sigma \boldsymbol\Sigma\mathbf{V}^\top  \)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{X}\mathbf{X}^\top =  (\mathbf{U}\boldsymbol\Sigma\mathbf{V}^\top)  (\mathbf{U}\boldsymbol\Sigma\mathbf{V}^\top)^\top =  (\mathbf{U}\boldsymbol\Sigma\mathbf{V}^\top)
(\mathbf{V}\boldsymbol\Sigma\mathbf{U}^\top) =  \mathbf{U}\boldsymbol\Sigma \boldsymbol\Sigma\mathbf{U}^\top\)</span></p></li>
</ul>
<p>Since the covariance matrices are symmetric matrices, by the spectral theorem such a matrix can be decomposed as <span class="math notranslate nohighlight">\(\mathbf{A} = \mathbf{P}\mathbf{D}\mathbf{P}^\top\)</span>.
For both covariance matrices, we can conclude that <span class="math notranslate nohighlight">\(\boldsymbol\Sigma\boldsymbol\Sigma\)</span> is a diagonal matrix containing :</p>
<ul class="simple">
<li><p>the eigenvalues of the covariances matrices. The eigenvalues are equal for both covariance matrices.</p></li>
<li><p>the squared singular values. That is singular values are square roots of the eigenvalues of the covariance matrices</p></li>
</ul>
<p>Like eigenvalues, it is <em>conventional</em> to order singular values in the diagonal of <span class="math notranslate nohighlight">\(\boldsymbol\Sigma\)</span> from larger to lower: <span class="math notranslate nohighlight">\(\sigma_1 &gt; \sigma_2 &gt; \ldots &gt; \sigma_r\)</span>. The columns of left and right singular matrices are ordered to make the corresponding singular vector match the position of the corresponding singular value.</p>
<div class="admonition-note-singular-values-and-variance admonition">
<p class="admonition-title">Note (singular values and variance)</p>
<p>The covariance matrix decomposition <span class="math notranslate nohighlight">\(\mathbf{A} = \mathbf{PDP}^\top\)</span> isolates the intrinsic variance of each variable in the diagonal matrix <span class="math notranslate nohighlight">\(\mathbf{D}\)</span>: these are the eigenvalues of the covariance matrix.
Since singular values are square roots of the eigenvalues, they also represent variance: the larger the singular value, the larger the intrinsic variance of the variable.</p>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="_images/c7a980a4c8e054c633bf409f01528f1dfed01f69d06a59dba6cbfddeb97d24e8.png" src="_images/c7a980a4c8e054c633bf409f01528f1dfed01f69d06a59dba6cbfddeb97d24e8.png" />
</div>
</div>
<p>This figure illlustrates the scatter plots of two bivariate data sets together with their respective covariance matrices. The red arrows are the eigenvectors of the covariance matrix scaled by their eigenvalues.
The left plot is a dataset whose covariance matrix is diagonal : the covariance between variables is zero and the eigenvalues are found on the diagonal of the actual covariance matrix.
The right plot is a dataset whose covariance matrix is not diagonal. The eigenvectors and eigenvalues provide both the directions of maximal variance and the actual values of the variances
in the diagonal matrix <span class="math notranslate nohighlight">\(\mathbf{D}\)</span> resulting from spectral decomposition.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In case <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> is a term-document matrix, the lines of <span class="math notranslate nohighlight">\(\mathbf{U}\)</span> encode term vectors (or word embeddings) of size <span class="math notranslate nohighlight">\(r\)</span> or smaller.
The columns of <span class="math notranslate nohighlight">\(\mathbf{V}^\top\)</span> encode document vectors (or document embeddings) of size <span class="math notranslate nohighlight">\(r\)</span> or smaller.</p>
</div>
</section>
<section id="low-rank-representation">
<h2>Low Rank representation<a class="headerlink" href="#low-rank-representation" title="Permalink to this heading">#</a></h2>
<p>SVD is generally used in its truncated form. In exact SVD, the value <span class="math notranslate nohighlight">\(r\)</span> is set to be the number of singular values.
In truncated SVD, <span class="math notranslate nohighlight">\(\boldsymbol\Sigma \in \mathbb{R}^{t\times t}\)</span> with <span class="math notranslate nohighlight">\(t &lt; r\)</span>.
Since the singular values can be ordered according to their variance, greater variance comes first, lower comes last, in <span class="math notranslate nohighlight">\(\text{diag}(\boldsymbol\Sigma)\)</span>.
Removing the smaller singular values, with lower variance, removes the details of the input data.</p>
<figure class="align-default" id="svd-fig">
<a class="reference internal image-reference" href="_images/svd.pdf"><img alt="_images/svd.pdf" src="_images/svd.pdf" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 5 </span><span class="caption-text">The Truncated SVD drops the singular values with least variance and their related left and right singular vectors</span><a class="headerlink" href="#svd-fig" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Remark that reducing <span class="math notranslate nohighlight">\(r\)</span> to <span class="math notranslate nohighlight">\(t\)</span> does not prevent from reconstructing an approximation of <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> with the same shape. We illustrate that with an image example.
The raccoon is a matrix <span class="math notranslate nohighlight">\(\mathbf{X}\in [0,255]^{n\times m}\)</span> encoding the grayscale image pixelwise. Computing its SVD and then reconstructing the image by matrix multiplication
yields the following results:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p><span class="math notranslate nohighlight">\(\mathbf{X}\)</span> full</p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(\hat{\mathbf{X}}\)</span> (t=100)</p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(\hat{\mathbf{X}}\)</span> (t=60)</p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(\hat{\mathbf{X}}\)</span> (t=20)</p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(\hat{\mathbf{X}}\)</span> (t=10)</p></th>
<th class="head text-right"><p><span class="math notranslate nohighlight">\(\hat{\mathbf{X}}\)</span> (t=2)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><img alt="raccoon1" src="_images/raton_full.png" /></p></td>
<td><p><img alt="raccoon100" src="_images/raton100.png" /></p></td>
<td><p><img alt="raccoon60" src="_images/raton60.png" /></p></td>
<td><p><img alt="raccoon20" src="_images/raton20.png" /></p></td>
<td><p><img alt="raccoon10" src="_images/raton10.png" /></p></td>
<td class="text-right"><p><img alt="raccoon2.png" src="_images/raton2.png" /></p></td>
</tr>
</tbody>
</table>
<p>where each picture keeps the <span class="math notranslate nohighlight">\(\sigma_1 \ldots \sigma_t\)</span> larger singular values and their corresponding singular vectors to compute the reconstruction <span class="math notranslate nohighlight">\(\hat{\mathbf{X}}\)</span>.
As can be seen the low rank reconstruction creates a smoothing effect. The less singular values used in the reconstruction, the less variance is kept, the more approximative the image becomes.</p>
<p>When the matrix is not an image, but rather a count-based term-document matrix, SVD can be used in principle to generate either a denoised reconstruction of the text-document matrix, where ignoring small singular values
may remove random residual noise gathered when counting. But in practice, SVD is mostly used to :</p>
<ul class="simple">
<li><p>get low dimensional word or document embeddings, denoising the raw counts</p></li>
<li><p>get 2D embeddings that can be used for graphical visualization</p></li>
</ul>
</section>
<section id="latent-semantic-analysis">
<h2>Latent Semantic Analysis<a class="headerlink" href="#latent-semantic-analysis" title="Permalink to this heading">#</a></h2>
<p>The application of SVD to term-document matrices is called <strong>Latent Semantic Analysis</strong> (or LSA). LSA relies on a more elaborate encoding of the term-document matrices than the one introduced so far
by means of a TF-IDF transformation of the counts. This transformation is motivated by the particular pattern of count distributions gathered from textual data.</p>
<p><strong>Zipf law of word counts</strong> Counts from text, provided a sufficiently large text, do invariably follow a distribution called the Zipf law of frequencies.
Given a vocabulary <span class="math notranslate nohighlight">\(W\)</span> and a counting function <span class="math notranslate nohighlight">\(c: W \mapsto \mathbb{N}\)</span>, a <em>ranked distribution</em> <span class="math notranslate nohighlight">\(w_1\ldots w_n\)</span> orders the words according to their counts
such that <span class="math notranslate nohighlight">\(c(w_i) &gt; c(w_j) \Leftrightarrow i &lt; j\)</span>.  The Zipf law states that</p>
<div class="math notranslate nohighlight">
\[
c(w_r) \approx \frac{c(w_1)}{r}
\]</div>
<p>that is the expected counts of a word is approximatively inversely proportional to its rank. Zipf law has fundamental effects in the design of statistical models of language.
It entails that few words are highly frequent and most of the vocabulary has low frequency. The specific consequences are:</p>
<ul class="simple">
<li><p>Highly frequent words are likely to be uninformative and to be present in every document</p></li>
<li><p>Informative words are highly infrequent, half of the vocabulary has frequency 1, and may sometimes occur in documents “by chance”, introducing “counting noise”</p></li>
</ul>
<div class="admonition-an-example-from-shakespeare admonition">
<p class="admonition-title">An example from Shakespeare </p>
<p>Here is an example count pattern gathered from works of Shakespeare.
It is a typical Zipf pattern. The x axis is ordered according to the word rank and y axis is the word frequency (logarithmic scale).</p>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="_images/79e6d378ffe42591d38c67f8c0e0468c8e968baa64ba2deab0c3c78da93eadc5.png" src="_images/79e6d378ffe42591d38c67f8c0e0468c8e968baa64ba2deab0c3c78da93eadc5.png" />
</div>
</div>
<p>The <strong>TF-IDF</strong>  aims at filling term document matrices by transforming the raw frequency counts.
The transformation builds on two submetrics: True Frequency and Inverse Document Frequency.</p>
<ul class="simple">
<li><p>True Frequency of word <span class="math notranslate nohighlight">\(w\)</span> in document <span class="math notranslate nohighlight">\(d\)</span> is simply the number of occurrences of <span class="math notranslate nohighlight">\(w\)</span> in <span class="math notranslate nohighlight">\(d\)</span> divided by the number of tokens in <span class="math notranslate nohighlight">\(d\)</span>.
Let <span class="math notranslate nohighlight">\(c:W\times D\mapsto \mathbb{N}\)</span> be a per document counting function.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\text{TF}(w,d) = \frac{c(w,d)}{\sum_{w' \in d} c(w',d)} 
\]</div>
<ul class="simple">
<li><p>Inverse Document Frequency of a word <span class="math notranslate nohighlight">\(w\)</span> in a collection of documents <span class="math notranslate nohighlight">\(D\)</span> aims to measure the informativeness of the word <span class="math notranslate nohighlight">\(w\)</span>. Does it occur in every document or in a more specific subset ?</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\text{IDF}(w, D) = \log \frac{|D|}{ \sum_{d \in D}    \mathbb{1}[ c(w,d) &gt; 0 ]  }
\]</div>
<p>The TF-IDF metric combines the two:</p>
<div class="math notranslate nohighlight">
\[
\text{TF-IDF}(w,d,D) = TF(w,d) \times IDF(w,D)
\]</div>
<div class="admonition-note admonition">
<p class="admonition-title">Note</p>
<p>Observe the IDF function for a collection <span class="math notranslate nohighlight">\(D\)</span> of 100 documents. The more a word occurs in many different documents the more the IDF function downweights  its True Frequency towards 0</p>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="_images/c1af47c99478d0151531d298ffbb3fd55e980ee758c4cf4b36067cc213ac6bf4.png" src="_images/c1af47c99478d0151531d298ffbb3fd55e980ee758c4cf4b36067cc213ac6bf4.png" />
</div>
</div>
</section>
<section id="example-in-python">
<h2>Example in Python<a class="headerlink" href="#example-in-python" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">string</span>
<span class="kn">import</span> <span class="nn">wikipedia</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction</span> <span class="kn">import</span> <span class="n">text</span>

<span class="c1">#Gather data</span>
<span class="n">wikipages</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Games of Thrones&quot;</span><span class="p">,</span> <span class="s2">&quot;Harry Potter&quot;</span><span class="p">,</span> <span class="s2">&quot;The Lord of the Rings&quot;</span><span class="p">,</span> <span class="s2">&quot;Algorithm&quot;</span><span class="p">,</span> 
             <span class="s2">&quot;Artificial Intelligence&quot;</span><span class="p">,</span><span class="s2">&quot;Computer Science&quot;</span><span class="p">,</span> <span class="s2">&quot;Linguistics&quot;</span><span class="p">,</span><span class="s2">&quot;Roswell Incident&quot;</span><span class="p">,</span>
			 <span class="s2">&quot;Solar System&quot;</span><span class="p">,</span><span class="s2">&quot;Milky Way&quot;</span><span class="p">,</span><span class="s2">&quot;Tropical cyclone&quot;</span><span class="p">,</span><span class="s2">&quot;Typhoon&quot;</span><span class="p">,</span>
			 <span class="s2">&quot;Tsunami&quot;</span><span class="p">,</span><span class="s2">&quot;Wine&quot;</span><span class="p">,</span><span class="s2">&quot;Beer&quot;</span><span class="p">]</span>

<span class="n">dataset</span>   <span class="o">=</span> <span class="p">[</span><span class="n">wikipedia</span><span class="o">.</span><span class="n">page</span><span class="p">(</span><span class="n">page</span><span class="p">,</span><span class="n">auto_suggest</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">summary</span> <span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">wikipages</span><span class="p">]</span>


<span class="c1">#Preprocessing (removes tokens with non ascii encoding and stop words)</span>
<span class="n">tokenized_set</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
    <span class="n">page</span>   <span class="o">=</span> <span class="n">page</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">page</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> 
	        <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">char</span> <span class="ow">in</span> <span class="n">string</span><span class="o">.</span><span class="n">ascii_letters</span> <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">token</span><span class="p">)</span>
			<span class="ow">and</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">ENGLISH_STOP_WORDS</span><span class="p">]</span>
    <span class="n">tokenized_set</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>

<span class="c1">#Vocabulary</span>
<span class="n">vocabulary</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">token</span> <span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">tokenized_set</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">page</span><span class="p">)</span> 
<span class="n">idx2word</span>   <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span>
<span class="n">word2idx</span>   <span class="o">=</span> <span class="p">{</span><span class="n">token</span><span class="p">:</span><span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span><span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">idx2word</span><span class="p">)}</span>


<span class="c1">#Term-Document matrix</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">tdmat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">idx2word</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">wikipages</span><span class="p">)))</span>


<span class="c1">##TF</span>
<span class="k">for</span> <span class="n">pidx</span><span class="p">,</span> <span class="n">page</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tokenized_set</span><span class="p">):</span>
	<span class="n">counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">page</span><span class="p">)</span>
	<span class="n">total</span>  <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">counts</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
	<span class="k">for</span> <span class="n">word</span><span class="p">,</span><span class="n">count</span> <span class="ow">in</span> <span class="n">counts</span><span class="o">.</span><span class="n">most_common</span><span class="p">():</span>
		<span class="n">tdmat</span><span class="p">[</span><span class="n">word2idx</span><span class="p">[</span><span class="n">word</span><span class="p">],</span><span class="n">pidx</span><span class="p">]</span> <span class="o">=</span> <span class="n">count</span><span class="o">/</span><span class="n">total</span>

<span class="c1">##TF-IDF</span>
<span class="n">D</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenized_set</span><span class="p">)</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span><span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tdmat</span><span class="p">):</span>
	<span class="n">idf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">D</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">line</span><span class="p">)))</span>
	<span class="n">tdmat</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">*=</span> <span class="n">idf</span>
		
<span class="c1">#prints the first few lines of the term document matrix</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tdmat</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span> 


<span class="c1"># Computes the SVD</span>
<span class="kn">from</span> <span class="nn">numpy.linalg</span> <span class="kn">import</span> <span class="n">svd</span>

<span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">Vt</span> <span class="o">=</span> <span class="n">svd</span><span class="p">(</span><span class="n">tdmat</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[0.         0.         0.         0.         0.0166138  0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.00988339 0.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.01893741 0.        ]
 [0.         0.         0.         0.         0.         0.
  0.01769967 0.         0.         0.         0.         0.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.01565347
  0.         0.         0.        ]]
</pre></div>
</div>
</div>
</div>
<p>that’s it ! We have both the term document matrix with TF-IDF values and the SVD decomposition.</p>
<section id="lsa-and-visualisation">
<h3>LSA and visualisation<a class="headerlink" href="#lsa-and-visualisation" title="Permalink to this heading">#</a></h3>
<p>Given the term document matrix we can compute the SVD and use it for <strong>visualisation</strong> of words or documents in two dimensions:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Truncation</span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">Uk</span>   <span class="o">=</span>  <span class="n">U</span><span class="p">[:,:</span><span class="n">k</span><span class="p">]</span>
<span class="n">Sk</span>   <span class="o">=</span>  <span class="n">S</span><span class="p">[:</span><span class="n">k</span><span class="p">]</span>
<span class="n">Vtk</span>  <span class="o">=</span>  <span class="n">Vt</span><span class="p">[:</span><span class="n">k</span><span class="p">,:]</span>

<span class="c1">#Plotting (20 first words only, all documents)</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>

<span class="n">mwords</span><span class="o">=</span><span class="mi">20</span>  
<span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">x</span><span class="p">,</span><span class="n">y</span>    <span class="o">=</span> <span class="n">Uk</span><span class="p">[:</span><span class="n">mwords</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span><span class="n">Uk</span><span class="p">[:</span><span class="n">mwords</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Words&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span><span class="n">labelrotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="k">for</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">idx2word</span><span class="p">):</span>
	<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">label</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>


<span class="n">x</span><span class="p">,</span><span class="n">y</span>    <span class="o">=</span> <span class="n">Vtk</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span><span class="n">Vtk</span><span class="p">[</span><span class="mi">1</span><span class="p">,:]</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Documents&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span><span class="n">labelrotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="k">for</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">wikipages</span><span class="p">):</span>
	<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">label</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">set_figwidth</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/15113a9d8ed569bf13e2c6f032bc365082aacfb0741662e4fb3846209df441e1.png" src="_images/15113a9d8ed569bf13e2c6f032bc365082aacfb0741662e4fb3846209df441e1.png" />
</div>
</div>
<p>These 2D plots use only the first 2 singular values of SVD. This drops a lot of variance from the original high dimensional data
and are to be viewed as mirrors of high dimensional data but as distorting mirrors.</p>
<p>To get a better idea of the distortion importance, it is also worthwhile to look at other viewing methods for high dimensional covariance matrices. Here we provide a method for viewing the Document x Document covariance matrix under different levels of approximation (truncation)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">covariance_plot</span><span class="p">(</span><span class="n">document_matrix</span><span class="p">,</span><span class="n">document_labels</span><span class="p">,</span><span class="n">fig</span><span class="p">,</span><span class="n">axis</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">center</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">colorbar</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">	Args:</span>
<span class="sd">	   document_matrix (array): array whose columns are document vectors</span>
<span class="sd">	   document_labels (list) : list of strings with document names</span>
<span class="sd">	   fig    : the figure where to plot the covariance matrix</span>
<span class="sd">	   axis   : the axis where to plot the covariance matrix</span>
<span class="sd">	   center : if true performs centering of the document vectors</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">document_labels</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">N</span> <span class="o">==</span> <span class="n">document_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">center</span><span class="p">:</span>
        <span class="n">document_matrix</span> <span class="o">=</span> <span class="n">document_matrix</span>  <span class="o">-</span> <span class="n">document_matrix</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>		
		
    <span class="n">covar</span> <span class="o">=</span> <span class="n">document_matrix</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">document_matrix</span>
	
    <span class="n">im</span> <span class="o">=</span> <span class="n">axis</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">covar</span><span class="p">)</span>
    <span class="n">axis</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">))</span>
    <span class="n">axis</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">))</span>
    <span class="n">axis</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">document_labels</span><span class="p">,</span><span class="n">rotation</span> <span class="o">=</span> <span class="mi">90</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">axis</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">document_labels</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">axis</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">im</span>

<span class="k">def</span> <span class="nf">truncate</span><span class="p">(</span><span class="n">U</span><span class="p">,</span><span class="n">S</span><span class="p">,</span><span class="n">Vt</span><span class="p">,</span><span class="n">k</span><span class="p">):</span>
	<span class="k">return</span> <span class="p">(</span><span class="n">U</span><span class="p">[:,:</span><span class="n">k</span><span class="p">],</span> <span class="n">S</span><span class="p">[:</span><span class="n">k</span><span class="p">],</span><span class="n">Vt</span><span class="p">[:</span><span class="n">k</span><span class="p">,:])</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">covariance_plot</span><span class="p">(</span><span class="n">Vt</span><span class="p">,</span><span class="n">wikipages</span><span class="p">,</span><span class="n">fig</span><span class="p">,</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="s2">&quot;Heatmap (k=15)&quot;</span><span class="p">,</span><span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">covariance_plot</span><span class="p">(</span><span class="n">truncate</span><span class="p">(</span><span class="n">U</span><span class="p">,</span><span class="n">S</span><span class="p">,</span><span class="n">Vt</span><span class="p">,</span><span class="mi">10</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">wikipages</span><span class="p">,</span><span class="n">fig</span><span class="p">,</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="s2">&quot;Heatmap (k=10)&quot;</span><span class="p">,</span><span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">covariance_plot</span><span class="p">(</span><span class="n">truncate</span><span class="p">(</span><span class="n">U</span><span class="p">,</span><span class="n">S</span><span class="p">,</span><span class="n">Vt</span><span class="p">,</span><span class="mi">2</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">wikipages</span><span class="p">,</span><span class="n">fig</span><span class="p">,</span><span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="s2">&quot;Heatmap (k=2)&quot;</span><span class="p">,</span><span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">colorbar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">cbar</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/d3a872eeef41ebc975c6b7a6f08f97b8e5a0858b2e085fdbf8416466f17c7b85.png" src="_images/d3a872eeef41ebc975c6b7a6f08f97b8e5a0858b2e085fdbf8416466f17c7b85.png" />
</div>
</div>
</section>
<section id="topic-analysis">
<h3>Topic analysis<a class="headerlink" href="#topic-analysis" title="Permalink to this heading">#</a></h3>
<p>Latent semantic analysis is also used to identify <strong>latent topics</strong> (or latent concepts) in documents.
Each element of a document vector (a column of the <em>topic-document matrix</em> <span class="math notranslate nohighlight">\(\mathbf{V}^\top\)</span>) can be interpreted as an indicator of a topic representation in a document.</p>
<p>Considering the “Milky Way” document vector in a non truncated SVD we can get a plot of the topics represented in the Milky way document:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">docidx</span> <span class="o">=</span> <span class="n">wikipages</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s1">&#39;Milky Way&#39;</span><span class="p">)</span>
<span class="n">docvec</span> <span class="o">=</span> <span class="n">Vt</span><span class="p">[:,</span><span class="n">docidx</span><span class="p">]</span>

<span class="n">plot</span>  <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">docvec</span><span class="p">))</span> <span class="p">,</span><span class="n">docvec</span><span class="p">,</span><span class="n">tick_label</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;topic-</span><span class="si">{</span><span class="n">d</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">docvec</span><span class="p">))]</span> <span class="p">)</span>
<span class="n">ticks</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">title</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Latent topics in the document &quot;Milky Way&quot;&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b6bec9ac970337ef302a5fbac0ace5d91bda5bce21f38ce712331b2245195418.png" src="_images/b6bec9ac970337ef302a5fbac0ace5d91bda5bce21f38ce712331b2245195418.png" />
</div>
</div>
<p>Now how do we interpret these latent topics ? For the <em>topic documents matrix</em> <span class="math notranslate nohighlight">\(\mathbf{V}^\top\)</span> each line represents a latent topic vector while for the <em>term-topic matrix</em> <span class="math notranslate nohighlight">\(\mathbf{U}\)</span> each <em>i</em>-th column represents the latent topic corresponding to the <em>i</em>-th line in <span class="math notranslate nohighlight">\(\mathbf{V}^\top\)</span>. We can get elements of interpretation of the latent topic by retrieving terms with the highest scores in the topic.  Here we attempt to get an interpretation for topic-3 and topic-9.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Matching terms with their scores for 3rd topic</span>
<span class="n">scored_terms</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">U</span><span class="p">[:,</span><span class="mi">3</span><span class="p">],</span> <span class="n">idx2word</span><span class="p">)</span>

<span class="n">k</span> <span class="o">=</span> <span class="mi">10</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;* Topic-3 top </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1"> terms *&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">score</span><span class="p">,</span><span class="n">term</span> <span class="ow">in</span>  <span class="nb">sorted</span><span class="p">(</span><span class="n">scored_terms</span><span class="p">,</span><span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span><span class="n">k</span><span class="p">]:</span>
   <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">term</span><span class="si">}</span><span class="s1"> : </span><span class="si">{</span><span class="n">score</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">()</span>

<span class="c1">#Matching terms with their scores for the 9th topic</span>
<span class="n">scored_terms</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">U</span><span class="p">[:,</span><span class="mi">9</span><span class="p">],</span> <span class="n">idx2word</span><span class="p">)</span>

<span class="n">k</span> <span class="o">=</span> <span class="mi">10</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;* Topic-9 top </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1"> terms *&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">score</span><span class="p">,</span><span class="n">term</span> <span class="ow">in</span>  <span class="nb">sorted</span><span class="p">(</span><span class="n">scored_terms</span><span class="p">,</span><span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span><span class="n">k</span><span class="p">]:</span>
   <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">term</span><span class="si">}</span><span class="s1"> : </span><span class="si">{</span><span class="n">score</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>* Topic-3 top 10 terms *
tropical : 0.2473349912556632
typhoon : 0.16054533750297004
beer : 0.15078877006092853
pub : 0.11309157754569639
cyclones : 0.11172269458637739
cyclone : 0.11067925583560152
pacific : 0.10555352250209457
warning : 0.08079859784660108
fermentation : 0.07539438503046426
brewing : 0.07539438503046426

* Topic-9 top 10 terms *
finite : 0.22797970518123434
correct : 0.22797970518123434
state : 0.1519864701208229
problem : 0.1519864701208229
optimal : 0.1519864701208229
initial : 0.1519864701208229
automated : 0.1519864701208229
algorithms : 0.1519864701208229
algorithm : 0.1519864701208229
tsunamis : 0.12509565364814143
</pre></div>
</div>
</div>
</div>
</section>
</section>
<div class="toctree-wrapper compound">
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="graphs.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Applications to graph analysis : the PageRank algorithm</p>
      </div>
    </a>
    <a class="right-next"
       href="ir.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Information retrieval exercise</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-algebra-for-descriptive-multivariate-statistics">Linear algebra for descriptive multivariate statistics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#covariance-matrices">Covariance matrices</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#singular-value-decomposition">Singular Value Decomposition</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#low-rank-representation">Low Rank representation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#latent-semantic-analysis">Latent Semantic Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-in-python">Example in Python</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lsa-and-visualisation">LSA and visualisation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topic-analysis">Topic analysis</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Benoit Crabbé
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=bd9e20870c6007c4c509"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=bd9e20870c6007c4c509"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>