{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dbd2010-373c-422c-884d-d4638aac43ea",
   "metadata": {},
   "source": [
    "Search engine\n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c29a87-18b7-4e36-9d0d-3b0abf64ece9",
   "metadata": {},
   "source": [
    "The dataset\n",
    "-----\n",
    "\n",
    "In this exercise we use a wikipedia *Star Wars* dataset. \n",
    "This is a small dataset of wikipedia abstracts on *Star Wars* related topics. \n",
    "\n",
    "The dataset is a couple $\\langle L,Q \\rangle$:\n",
    "- $L:I \\mapsto D$ is a library function. Each document has a unique index $i\\in I$ that maps to the document string $d\\in D$.\n",
    "- $Q = (q_1,i_1) \\ldots (q_n,i_n)$  is a list of reference (queries,index) couples.\n",
    "  Each mapping a query string to the index of a page\n",
    "\n",
    "We further have a set of links ${\\cal L} \\subseteq I\\times I$ between the document indexes. \n",
    "These links are encoded as a graph whose vertices are indexes and edges are couples of indexes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f53f58a2-4eab-4df0-b4a7-2ae6c1bfb6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "\n",
    "# This code gathers wikipedia pages and creates the dataset from these pages.\n",
    "# The queries are the page titles, the documents are paragraphs randomly selected in the pages\n",
    "# We further create a graph of links between document ids expressed as an adjacency matrix\n",
    "\n",
    "pages = [\n",
    "           \"Luke Skywalker\",\"Admiral Ackbar\",\"Boba Fett\",\"C-3PO\",\n",
    "           \"Chewbacca\",\"Count Dooku\",\"Darth Maul\",\"Darth Vader\",\"General Grievous\",\n",
    "           \"Greedo\",\"Han Solo\",\"Jabba the Hutt\",\"Jango Fett\",\"Jar Jar Binks\",\n",
    "           \"Lando Calrissian\",\"Leia Organa\",\"Mace Windu\",\"Obi-Wan Kenobi\",\n",
    "           \"PadmÃ© Amidala\",\"Palpatine\",\"Qui-Gon Jinn\",\"R2-D2\",\"Saw Gerrera\",\"Yoda\"\n",
    "          ]\n",
    "\n",
    "\n",
    "# Gets the wikipedia pages\n",
    "def build_library(nodeset,k):\n",
    "    \"\"\"\n",
    "    Builds and indexes the documents and queries from wikipedia pages\n",
    "    \n",
    "    Args: \n",
    "       nodeset (list): a list of strings, titles of wikipedia pages\n",
    "       k        (int): the number of paragraphs to sample for some wikipedia page\n",
    "    Returns:\n",
    "        a dict of documents idx:str , \n",
    "        a list of query:idx. A single query may have multiple idx in the list         \n",
    "    \"\"\"\n",
    "    random.seed(77)\n",
    "    nodes2pages = {node:wikipedia.page(node,auto_suggest=False) for node in nodeset}\n",
    "\n",
    "    idx       = 1\n",
    "    documents = {}\n",
    "    queries   = []\n",
    "    \n",
    "    for node in nodeset:\n",
    "        cpage      = nodes2pages[node]\n",
    "        query      = cpage.title\n",
    "        paragraphs = [line for line in cpage.content.split('\\n') if len(line) > 80 and not line.startswith('=') ]\n",
    "        paragraphs = random.sample(paragraphs,k)\n",
    "        \n",
    "        for parag in paragraphs:\n",
    "             documents[idx] = parag\n",
    "             queries.append( (query,idx) )\n",
    "             idx += 1\n",
    "    return documents, queries\n",
    "\n",
    "\n",
    "def link_documents(library,queries):\n",
    "    \"\"\"\n",
    "    Creates a web structure for a set of documents.\n",
    "    Adds a link from i to j if the content of i contains a mention of j\n",
    "    \n",
    "    Args:\n",
    "        library (dict): a dict of idx:documents\n",
    "        queries (list): a list of (query,idx)\n",
    "    Returns:\n",
    "        a networkx DiGraph\n",
    "    \"\"\"\n",
    "    graph  = nx.DiGraph()\n",
    "    docids = [docidx for docidx in library] \n",
    "    graph.add_nodes_from(docids)\n",
    "\n",
    "    idx2queries = {idx:q for q,idx in queries}\n",
    "    for docidx, doc in library.items():\n",
    "        for qidx,title in idx2queries.items():\n",
    "            if title.lower() in doc.lower():\n",
    "                graph.add_edge(docidx,qidx)\n",
    "    return graph\n",
    "\n",
    "\n",
    "\n",
    "documents,queries = build_library(pages,10)\n",
    "docids, adjacency = nx.to_numpy_array(link_documents(documents,queries))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56031bdb-fcf6-4ffa-974a-ab56431961bd",
   "metadata": {},
   "source": [
    "PageRank\n",
    "----\n",
    "\n",
    "In this section we want to implement a PageRank algorithm for the Star Wars documents.\n",
    "We already have the adjacency matrix. The page rank function outputs a dictionary,\n",
    "or the function $PR:I\\mapsto \\mathbb{R}$ where each document index is mapped to its PageRank score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "601c319f-c861-40e4-9ab9-dadd94c49140",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c791eb8e30535207",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Error = 0.03943148751430696\n",
      "Iteration 1, Error = 0.008090244072429828\n",
      "Iteration 2, Error = 0.004505849497440606\n",
      "Iteration 3, Error = 0.002876153265294122\n",
      "Iteration 4, Error = 0.001943725514686239\n",
      "Iteration 5, Error = 0.001342050047285424\n",
      "Iteration 6, Error = 0.0009335915285161231\n",
      "[0.00333813 0.00333813 0.00333813 0.00333813 0.00333813 0.00333813\n",
      " 0.00333813 0.00333813 0.00333813 0.00333813 0.00166183 0.00166183\n",
      " 0.00166183 0.00166183 0.00166183 0.00166183 0.00166183 0.00166183\n",
      " 0.00166183 0.00166183 0.00320295 0.00320295 0.00320295 0.00320295\n",
      " 0.00320295 0.00320295 0.00320295 0.00320295 0.00320295 0.00320295\n",
      " 0.0041216  0.0041216  0.0041216  0.0041216  0.0041216  0.0041216\n",
      " 0.0041216  0.0041216  0.0041216  0.0041216  0.01082599 0.01082599\n",
      " 0.01082599 0.01082599 0.01082599 0.01082599 0.01082599 0.01082599\n",
      " 0.01082599 0.01082599 0.00344512 0.00344512 0.00344512 0.00344512\n",
      " 0.00344512 0.00344512 0.00344512 0.00344512 0.00344512 0.00344512\n",
      " 0.00326779 0.00326779 0.00326779 0.00326779 0.00326779 0.00326779\n",
      " 0.00326779 0.00326779 0.00326779 0.00326779 0.00726451 0.00726451\n",
      " 0.00726451 0.00726451 0.00726451 0.00726451 0.00726451 0.00726451\n",
      " 0.00726451 0.00726451 0.00340535 0.00340535 0.00340535 0.00340535\n",
      " 0.00340535 0.00340535 0.00340535 0.00340535 0.00340535 0.00340535\n",
      " 0.00447732 0.00447732 0.00447732 0.00447732 0.00447732 0.00447732\n",
      " 0.00447732 0.00447732 0.00447732 0.00447732 0.00299083 0.00299083\n",
      " 0.00299083 0.00299083 0.00299083 0.00299083 0.00299083 0.00299083\n",
      " 0.00299083 0.00299083 0.00383103 0.00383103 0.00383103 0.00383103\n",
      " 0.00383103 0.00383103 0.00383103 0.00383103 0.00383103 0.00383103\n",
      " 0.00273161 0.00273161 0.00273161 0.00273161 0.00273161 0.00273161\n",
      " 0.00273161 0.00273161 0.00273161 0.00273161 0.00186802 0.00186802\n",
      " 0.00186802 0.00186802 0.00186802 0.00186802 0.00186802 0.00186802\n",
      " 0.00186802 0.00186802 0.00329661 0.00329661 0.00329661 0.00329661\n",
      " 0.00329661 0.00329661 0.00329661 0.00329661 0.00329661 0.00329661\n",
      " 0.00263361 0.00263361 0.00263361 0.00263361 0.00263361 0.00263361\n",
      " 0.00263361 0.00263361 0.00263361 0.00263361 0.00294041 0.00294041\n",
      " 0.00294041 0.00294041 0.00294041 0.00294041 0.00294041 0.00294041\n",
      " 0.00294041 0.00294041 0.00482292 0.00482292 0.00482292 0.00482292\n",
      " 0.00482292 0.00482292 0.00482292 0.00482292 0.00482292 0.00482292\n",
      " 0.00350136 0.00350136 0.00350136 0.00350136 0.00350136 0.00350136\n",
      " 0.00350136 0.00350136 0.00350136 0.00350136 0.0057655  0.0057655\n",
      " 0.0057655  0.0057655  0.0057655  0.0057655  0.0057655  0.0057655\n",
      " 0.0057655  0.0057655  0.0021739  0.0021739  0.0021739  0.0021739\n",
      " 0.0021739  0.0021739  0.0021739  0.0021739  0.0021739  0.0021739\n",
      " 0.0059654  0.0059654  0.0059654  0.0059654  0.0059654  0.0059654\n",
      " 0.0059654  0.0059654  0.0059654  0.0059654  0.00223532 0.00223532\n",
      " 0.00223532 0.00223532 0.00223532 0.00223532 0.00223532 0.00223532\n",
      " 0.00223532 0.00223532 0.01023287 0.01023287 0.01023287 0.01023287\n",
      " 0.01023287 0.01023287 0.01023287 0.01023287 0.01023287 0.01023287]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def pagerank(adjacency,alpha=0.85,eps=0.001):\n",
    "    \"\"\"\n",
    "    Computes the PageRank of a dense adjacency matrix\n",
    "    Args:\n",
    "       adjacency (np.array): an adjacency matrix\n",
    "       alpha        (float): the alpha for mixing when creating the Google Matrix.  \n",
    "       eps          (float): epsilon for stopping PageRank iterations\n",
    "    Returns: \n",
    "        dict. A dictionary whose keys are document ids and values are document page ranks\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    n,_ = adjacency.shape\n",
    "\n",
    "    with np.errstate(divide='ignore',invalid='ignore'):\n",
    "      row_stochastic   = adjacency / adjacency.sum(axis=1,keepdims=True)\n",
    "      row_stochastic   = np.nan_to_num(row_stochastic,0.)\n",
    "\n",
    "    jump             = np.ones_like(row_stochastic) / n\n",
    "\n",
    "    google           = (alpha * row_stochastic + (1-alpha) * jump )\n",
    "    #ensure stochasticity for absorbing nodes\n",
    "    google           = google / google.sum(axis=1,keepdims=True) \n",
    "    #google matrix is eventually column stochastic\n",
    "    google = google.T\n",
    "\n",
    "\n",
    "    x   = np.random.random(n)\n",
    "    x  /= x.sum() \t                   #ensure probabilistic vector\n",
    "    error = float('inf')\n",
    "    idx = 0\n",
    "    while error >= eps:\n",
    "        xnext = google @ x\n",
    "        error = norm(xnext-x)\n",
    "        print(f'Iteration {idx}, Error = {error}')\n",
    "        x     = xnext\n",
    "        idx  += 1\n",
    "    return x\n",
    "\t\n",
    "    ### END SOLUTION\n",
    "\n",
    "pr = pagerank(adjacency)\n",
    "print(pr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8138735e-112a-4581-9d59-0c537d0d0a34",
   "metadata": {},
   "source": [
    "Document vectorization\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e515681b-582b-443c-a5a8-508116e334a2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Vector space based retrieval\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d372b69a-3816-4109-a2f4-979ff2082096",
   "metadata": {},
   "source": [
    "The ranking problem\n",
    "----\n",
    "\n",
    "We currently have two ranking methods:\n",
    "- PageRank, $PR(d)$, that scores documents wrt to their hyperlinks\n",
    "- The vector space model, $VSM(q,d)$, that scores documents wrt to their similarity with the query.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In this exercise, we propose to rank the search results according to the scores given by the formula:\n",
    "\n",
    "$$\n",
    "r(q,d) = \\lambda\\, VSM(q,d)  + (1-\\lambda)\\, PR(d)\n",
    "$$\n",
    "\n",
    "where $\\lambda \\in [0,1]$ is a weight. When set to 1 $PR$ is ignored and when set to 0 $VSM$ is ignored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570e5fdd-871b-49df-a379-292d34ee3190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
